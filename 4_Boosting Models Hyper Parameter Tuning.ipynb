{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Regression Data Analysis]\n",
    "# KaKR House Price Prediction - Boost Models Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전에서 확인했던 가장 성능이 좋은 **SUBMISSION #6** 에서의 feature를 이용해, 하이퍼파라미터 튜닝을 해봅니다.\n",
    "\n",
    "\n",
    "- Grid Search, Coarse Search, Finer Search 등 여러가지 방법을 이용해 봅니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from lightgbm import LGBMRegressor, plot_importance\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from scipy.stats import skew\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15035, 20), (6468, 19))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Data Loadrow_data = pd.read_csv(\"./data/train.csv\", index_col=['id'])\n",
    "row_test = pd.read_csv(\"./data/test.csv\", index_col=['id'])\n",
    "\n",
    "row_data.shape, row_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전에 만들었던 여러 함수를 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_preprocess(row_data, zipcode_rank_dict):\n",
    "    \n",
    "    data = row_data.copy()\n",
    "    \n",
    "    # price log transformation\n",
    "    if 'price' in data.columns:\n",
    "        data['log_price'] = np.log1p(data.price)\n",
    "    \n",
    "    # Date parsing\n",
    "    data['date'] = data['date'].apply(lambda i: i[:8])\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['year'] = data.date.dt.year\n",
    "    data['month'] = data.date.dt.month\n",
    "    data['day']= data.date.dt.day\n",
    "    data['year_month'] = data.date.dt.year * 100 + data.date.dt.month\n",
    "    data['day_of_week'] = data.date.dt.dayofweek\n",
    "    data['2015_or_not'] = data.year.apply(lambda i: 0 if i == 2014 else 1)\n",
    "    data['weekday_ohe'] = data.day_of_week.apply(lambda i: 1 if i in range(5) else 0)\n",
    "    data['saturday_ohe'] = data.day_of_week.apply(lambda i: 1 if i == 5 else 0)\n",
    "    data['sunday_ohe'] = data.day_of_week.apply(lambda i: 1 if i == 6 else 0)\n",
    "    \n",
    "    # yr_renovated\n",
    "    data['yr_renovated_ohe'] = data['yr_renovated'].apply(lambda i: 0 if i == 0 else 1)\n",
    "    \n",
    "    # zipcode : 위에서 zipcode_rank_dict를 만들어놔야 코드가 실행됨\n",
    "    data['zipcode_rank'] = 71 - data['zipcode'].apply(lambda i: zipcode_rank_dict[i])\n",
    "    \n",
    "    # lat / long\n",
    "    data['lat_scale'] = (data['lat'] - data['lat'].mean()) / data['lat'].std()\n",
    "    data['long_scale'] = (data['long'] - data['long'].mean()) / data['long'].std()\n",
    "    \n",
    "    # areas\n",
    "    data['sqft_living_scale'] = np.log1p(data['sqft_living'])\n",
    "    data['sqft_lot_scale'] = np.log1p(data['sqft_lot'])\n",
    "    data['sqft_living_diff'] = data['sqft_living15'] - data['sqft_living']\n",
    "    data['sqft_lot_diff'] = data['sqft_lot15'] - data['sqft_lot']\n",
    "    data.loc[data['sqft_living_diff'] < 0, 'sqft_living_diff_scale'] = -np.log1p(-data['sqft_living_diff'])\n",
    "    data.loc[data['sqft_living_diff'] >= 0, 'sqft_living_diff_scale'] = np.log1p(data['sqft_living_diff'])\n",
    "    data.loc[data['sqft_lot_diff'] < 0, 'sqft_lot_diff_scale'] = -np.log1p(-data['sqft_lot_diff'])\n",
    "    data.loc[data['sqft_lot_diff'] >= 0, 'sqft_lot_diff_scale'] = np.log1p(data['sqft_lot_diff'])\n",
    "    data['sqft_above_scale'] = np.log1p(data['sqft_above'])\n",
    "    data['sqft_basement_ohe'] = data.sqft_basement.apply(lambda i: 0 if i == 0 else 1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ziprank(data):\n",
    "    zipcode_rank = data.groupby(['zipcode']).mean().sort_values(by=['price'], \\\n",
    "                                                                ascending=False).reset_index()[['zipcode', 'price']]\n",
    "    zipcode_rank['rank'] = range(1, len(zipcode_rank)+1)\n",
    "    zipcode_rank_dict = zipcode_rank.set_index(['zipcode'])['rank'].to_dict()\n",
    "    \n",
    "    return zipcode_rank_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_rank_dict = get_ziprank(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15035, 42), (6468, 40))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = feature_preprocess(row_data, zipcode_rank_dict)\n",
    "test = feature_preprocess(row_test, zipcode_rank_dict)\n",
    "\n",
    "data.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_price', 'price'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.columns) - set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_cv(model, train, label):\n",
    "    rmse_list = np.sqrt(-cross_val_score(model, train, label, scoring='neg_mean_squared_error', cv=5))\n",
    "    \n",
    "    return np.round(np.mean(rmse_list), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_cv(model, train, label):\n",
    "    r2_list = cross_val_score(model, train, label, scoring='r2', cv=5)\n",
    "    \n",
    "    return np.round(np.mean(r2_list), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(model, y_test, y_pred):\n",
    "\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(models, train, label, rmse_=True):\n",
    "    df = {}\n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        df[model_name] = []\n",
    "        df[model_name].append(rmsle_cv(model, train, label))\n",
    "        df[model_name].append(r2_cv(model, train, label))\n",
    "        \n",
    "        if rmse:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            df[model_name].append(rmse(model, y_test, y_pred))\n",
    "        \n",
    "        if rmse:\n",
    "            score_df = pd.DataFrame(df, index=['RMSLE', 'R2 score', 'RMSE']).T.sort_values('R2 score', \\\n",
    "                                                                                           ascending=False)\n",
    "        else:\n",
    "            score_df = pd.DataFrame(df, index=['RMSLE', 'R2 score']).T.sort_values('R2 score', \\\n",
    "                                                                                   ascending=False)\n",
    "            \n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coef(models, sort_model):\n",
    "    coef = {}\n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        coef[model_name] = model.coef_\n",
    "\n",
    "    coef_df = pd.DataFrame(coef, index=train.columns)\n",
    "    \n",
    "    return coef_df.sort_values(sort_model.__class__.__name__, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_coefs(models):\n",
    "    if len(models) == 3:\n",
    "        figure, axs = plt.subplots(nrows=1, ncols=3)\n",
    "        figure.set_size_inches(18, 6)\n",
    "\n",
    "        for idx, model in enumerate(models):\n",
    "            model_name = model.__class__.__name__\n",
    "            sns.barplot(x=get_coef(models, model)[model_name].values, \\\n",
    "                        y=get_coef(models, model)[model_name].index, \\\n",
    "                        ax=axs[idx]).set_title(model_name)\n",
    "    else:\n",
    "        figure, axs = plt.subplots(nrows=2, ncols=2)\n",
    "        figure.set_size_inches(18, 12)\n",
    "\n",
    "        for idx, model in enumerate(models):\n",
    "            model_name = model.__class__.__name__\n",
    "            sns.barplot(x=get_coef(models, model)[model_name].values, \\\n",
    "                        y=get_coef(models, model)[model_name].index, \\\n",
    "                        ax=axs[idx//2][idx%2]).set_title(model_name)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_importances(models, data):\n",
    "    if type(models) != list:\n",
    "        model = models\n",
    "        model_name = model.__class__.__name__\n",
    "        importances = [i for i in zip(data.columns, model.feature_importances_)]\n",
    "        importances = sorted([[i[0], float(i[1])] for i in importances], key=lambda i: i[1], reverse=True)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=[i[1] for i in importances], y=[i[0] for i in importances]).set_title(model_name)\n",
    "    \n",
    "    elif len(models) == 3:\n",
    "        figure, axs = plt.subplots(nrows=1, ncols=3)\n",
    "        figure.set_size_inches(18, 6)\n",
    "\n",
    "        for idx, model in enumerate(models):\n",
    "            model_name = model.__class__.__name__\n",
    "            importances = [i for i in zip(train.columns, model.feature_importances_)]\n",
    "            importances = sorted([[i[0], float(i[1])] for i in importances], key=lambda i: i[1], reverse=True)\n",
    "            sns.barplot(x=[i[1] for i in importances], y=[i[0] for i in importances], \\\n",
    "                        ax=axs[idx]).set_title(model_name)\n",
    "\n",
    "    else:\n",
    "        figure, axs = plt.subplots(nrows=2, ncols=2)\n",
    "        figure.set_size_inches(18, 12)\n",
    "\n",
    "        for idx, model in enumerate(models):\n",
    "            model_name = model.__class__.__name__\n",
    "            importances = [i for i in zip(train.columns, model.feature_importances_)]\n",
    "            importances = sorted([[i[0], float(i[1])] for i in importances], key=lambda i: i[1], reverse=True)\n",
    "            sns.barplot(x=[i[1] for i in importances], y=[i[0] for i in importances], \\\n",
    "                        ax=axs[idx//2][idx%2]).set_title(model_name)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BlendingModels(models, x, y, sub_x):\n",
    "    for m in models : \n",
    "        m.fit(x.values, y)\n",
    "    \n",
    "    predictions = np.column_stack([\n",
    "        m.predict(sub_x.values) for m in models\n",
    "    ])\n",
    "    return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LetSubmit(y_pred, filename):\n",
    "    submission = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "    submission['price'] = y_pred\n",
    "    submission.to_csv(\"./submission/{}.csv\".format(filename), index_label=False, index=False)\n",
    "    submission_test = pd.read_csv(\"./submission.csv\")\n",
    "    \n",
    "    return submission_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Best Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GridSearchCV 메서드를 이용해 Best Parameter 를 출력하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BestParamsGrid(model, train, label, param_grid, verbose=2, n_jobs=5):\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', \\\n",
    "                              cv=5, verbose=verbose, n_jobs=n_jobs)\n",
    "    grid_model.fit(train, label)\n",
    "    rmsle = np.sqrt(-1 * grid_model.best_score_)\n",
    "    params_df = pd.DataFrame(grid_model.best_params_, index=[grid_model.__class__.__name__]).T\n",
    "\n",
    "    return grid_model, grid_model.best_params_, rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoarseSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정해져 있는 범위 내에서 랜덤으로 파라미터를 지정해 parameter searchm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoarseSearch(train, label, model_name='lgbm', num_epoch=100):\n",
    "    params_list = []\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    print(\"Let's start\\t\\t\\t\\t\")\n",
    "    \n",
    "    for epoch in range(1, num_epoch+1):\n",
    "        n_estimators = np.random.randint(low=100, high=1000)\n",
    "        max_depth = np.random.randint(low=2, high=100)\n",
    "        learning_rate = 10 ** -np.random.uniform(low=0, high=10)\n",
    "        subsample = np.random.uniform(low=0.4, high=1.0)\n",
    "        colsample_bytree = np.random.uniform(low=0.4, high=1.0)\n",
    "        colsample_bylevel = np.random.uniform(low=0.4, high=1.0)\n",
    "        num_leaves = np.random.randint(low=5, high=1000)\n",
    "        min_child_samples = np.random.randint(low=50, high=2000)\n",
    "        \n",
    "        if model_name == 'lgbm':\n",
    "            model = LGBMRegressor(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  subsample=subsample,\n",
    "                                  colsample_bylevel=colsample_bylevel,\n",
    "                                  colsample_bytree=colsample_bytree,\n",
    "                                  num_leaves=num_leaves,\n",
    "                                  min_child_samples=min_child_samples,\n",
    "                                  seed=37)\n",
    "            \n",
    "        elif model_name == 'xgb':\n",
    "            model = XGBRegressor(n_estimators=n_estimators,\n",
    "                                 max_depth=max_depth,\n",
    "                                 learning_rate=learning_rate,\n",
    "                                 subsample=subsample,\n",
    "                                 colsample_bylevel=colsample_bylevel,\n",
    "                                 colsample_bytree=colsample_bytree,\n",
    "                                 seed=37)\n",
    "\n",
    "        score = np.sqrt(-cross_val_score(model, train, label, cv=8, scoring='neg_mean_squared_error').mean())\n",
    "\n",
    "        params = {\n",
    "            'epoch': epoch,\n",
    "            'score': score,\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'learning_rate': learning_rate,\n",
    "            'subsample': subsample,\n",
    "            'colsample_bylevel': colsample_bylevel,\n",
    "            'colsample_bytree': colsample_bytree,\n",
    "            'num_leaves': num_leaves,\n",
    "            'min_child_samples': min_child_samples,\n",
    "        }\n",
    "\n",
    "        params_list.append(params)\n",
    "        \n",
    "        if (epoch == 1) | (epoch % (num_epoch//10) == 0):\n",
    "            print(\"{} epoch is now calculating . . .\\t\".format(epoch), str(datetime.now() - start_time)[:-7])\n",
    "            \n",
    "    finish_time = datetime.now()\n",
    "    print(\"All Coarse Searching is Finished\")\n",
    "    print(\"All taken:\", str(finish_time - start_time)[:-7])\n",
    "\n",
    "    params_df = pd.DataFrame.from_dict(params_list).sort_values('score')\n",
    "    print(params_df.shape)\n",
    "    \n",
    "    return params_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finer Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- parameter range를 인자로 받아 그 안에서 랜덤으로 파라미터를 지정해 parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinerSearch(train, label, param_range, model_name='lgbm', num_epoch=100):\n",
    "    params_list = []\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    print(\"Let's start\\t\\t\\t\\t\")\n",
    "    \n",
    "    for epoch in range(1, num_epoch+1):\n",
    "        n_estimators = np.random.randint(low=param_range['n_estimators'][0], \\\n",
    "                                         high=param_range['n_estimators'][1])\n",
    "        max_depth = np.random.randint(low=param_range['max_depth'][0], \\\n",
    "                                      high=param_range['max_depth'][1])\n",
    "        learning_rate = np.random.uniform(low=param_range['learning_rate'][0], \\\n",
    "                                          high=param_range['learning_rate'][1])\n",
    "        subsample = np.random.uniform(low=param_range['subsample'][0], \\\n",
    "                                      high=param_range['subsample'][1])\n",
    "        colsample_bytree = np.random.uniform(low=param_range['colsample_bytree'][0], \\\n",
    "                                             high=param_range['colsample_bytree'][1])\n",
    "        colsample_bylevel = np.random.uniform(low=param_range['colsample_bylevel'][0], \\\n",
    "                                              high=param_range['colsample_bylevel'][1])\n",
    "        num_leaves = np.random.randint(low=param_range['num_leaves'][0], \\\n",
    "                                       high=param_range['num_leaves'][1])\n",
    "        min_child_samples = np.random.randint(low=param_range['min_child_samples'][0], \\\n",
    "                                              high=param_range['min_child_samples'][1])\n",
    "        \n",
    "        if model_name == 'lgbm':\n",
    "            model = LGBMRegressor(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  subsample=subsample,\n",
    "                                  colsample_bylevel=colsample_bylevel,\n",
    "                                  colsample_bytree=colsample_bytree,\n",
    "                                  num_leaves=num_leaves,\n",
    "                                  min_child_samples=min_child_samples,\n",
    "                                  seed=37)\n",
    "            \n",
    "            score = np.sqrt(-cross_val_score(model, train, label, cv=8, \\\n",
    "                                             scoring='neg_mean_squared_error', n_jobs=5).mean())\n",
    "\n",
    "            params = {\n",
    "                'epoch': epoch,\n",
    "                'score': score,\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'learning_rate': learning_rate,\n",
    "                'subsample': subsample,\n",
    "                'colsample_bylevel': colsample_bylevel,\n",
    "                'colsample_bytree': colsample_bytree,\n",
    "                'num_leaves': num_leaves,\n",
    "                'min_child_samples': min_child_samples,\n",
    "            }\n",
    "            \n",
    "        elif model_name == 'xgb':\n",
    "            model = XGBRegressor(n_estimators=n_estimators,\n",
    "                                 max_depth=max_depth,\n",
    "                                 learning_rate=learning_rate,\n",
    "                                 seed=37)\n",
    "\n",
    "            score = np.sqrt(-cross_val_score(model, train, label, cv=8, \\\n",
    "                                             scoring='neg_mean_squared_error', n_jobs=5).mean())\n",
    "\n",
    "            params = {\n",
    "                'epoch': epoch,\n",
    "                'score': score,\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'learning_rate': learning_rate,\n",
    "            }\n",
    "\n",
    "        params_list.append(params)\n",
    "        \n",
    "        if (epoch == 1) | (epoch % (num_epoch//10) == 0):\n",
    "            print(\"{} epoch is now calculating . . .\\t\".format(epoch), str(datetime.now() - start_time)[:-7])\n",
    "            \n",
    "    finish_time = datetime.now()\n",
    "    print(\"All Coarse Searching is Finished\")\n",
    "    print(\"time duration:\", str(finish_time - start_time)[:-7])\n",
    "\n",
    "    params_df = pd.DataFrame.from_dict(params_list).sort_values('score')\n",
    "    print(params_df.shape)\n",
    "    \n",
    "    return params_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#SUBMISSION 6 : 3번 + `year_month`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전에서 가장 결과가 좋았던 SUBMISSION #6 을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', \\\n",
    "            'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', \\\n",
    "            'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'year_month']\n",
    "\n",
    "train = data[features]\n",
    "data['log_price'] = np.log1p(data.price)\n",
    "label = data['log_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor()\n",
    "xgboost = XGBRegressor()\n",
    "lightgbm = LGBMRegressor()\n",
    "rdforest = RandomForestRegressor()\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.2 s, sys: 1.15 s, total: 44.4 s\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "row_scores = get_scores(models, train, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>R2 score</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>121344.899765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.1831</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>131035.538895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1831</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>125378.071093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1878</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>120613.126149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>177622.786772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>182631.804389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.3586</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>249896.050268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            RMSLE  R2 score           RMSE\n",
       "LGBMRegressor              0.1634    0.9033  121344.899765\n",
       "XGBRegressor               0.1831    0.8786  131035.538895\n",
       "GradientBoostingRegressor  0.1831    0.8785  125378.071093\n",
       "RandomForestRegressor      0.1878    0.8739  120613.126149\n",
       "LinearRegression           0.2510    0.7717  177622.786772\n",
       "Ridge                      0.2510    0.7717  182631.804389\n",
       "Lasso                      0.3586    0.5339  249896.050268"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coarse / Finer Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 먼저 랜덤으로 러프하게 CoarseSearch 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\t\t\t\t 16:03:11\n",
      "1 epoch is now calculating . . .\t 16:03:12\n",
      "50 epoch is now calculating . . .\t 16:06:06\n",
      "100 epoch is now calculating . . .\t 16:08:16\n",
      "150 epoch is now calculating . . .\t 16:11:17\n",
      "200 epoch is now calculating . . .\t 16:13:14\n",
      "250 epoch is now calculating . . .\t 16:16:31\n",
      "300 epoch is now calculating . . .\t 16:18:55\n",
      "350 epoch is now calculating . . .\t 16:21:06\n",
      "400 epoch is now calculating . . .\t 16:24:28\n",
      "450 epoch is now calculating . . .\t 16:27:44\n",
      "500 epoch is now calculating . . .\t 16:30:25\n",
      "All Coarse Searching is Finished\n",
      "time duration: 0:27:13\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "lgbm_tuning_df = CoarseSearch(train, label, 'lgbm', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.654386</td>\n",
       "      <td>0.921381</td>\n",
       "      <td>181</td>\n",
       "      <td>0.043654</td>\n",
       "      <td>50</td>\n",
       "      <td>495</td>\n",
       "      <td>569</td>\n",
       "      <td>348</td>\n",
       "      <td>0.170261</td>\n",
       "      <td>0.936950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.702562</td>\n",
       "      <td>0.529863</td>\n",
       "      <td>153</td>\n",
       "      <td>0.045601</td>\n",
       "      <td>51</td>\n",
       "      <td>431</td>\n",
       "      <td>572</td>\n",
       "      <td>126</td>\n",
       "      <td>0.167844</td>\n",
       "      <td>0.860284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.453020</td>\n",
       "      <td>0.535704</td>\n",
       "      <td>344</td>\n",
       "      <td>0.055449</td>\n",
       "      <td>43</td>\n",
       "      <td>288</td>\n",
       "      <td>814</td>\n",
       "      <td>634</td>\n",
       "      <td>0.163962</td>\n",
       "      <td>0.943352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.901923</td>\n",
       "      <td>0.925929</td>\n",
       "      <td>229</td>\n",
       "      <td>0.076780</td>\n",
       "      <td>30</td>\n",
       "      <td>747</td>\n",
       "      <td>896</td>\n",
       "      <td>730</td>\n",
       "      <td>0.171047</td>\n",
       "      <td>0.569215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.971499</td>\n",
       "      <td>0.814491</td>\n",
       "      <td>314</td>\n",
       "      <td>0.098614</td>\n",
       "      <td>82</td>\n",
       "      <td>416</td>\n",
       "      <td>293</td>\n",
       "      <td>568</td>\n",
       "      <td>0.167425</td>\n",
       "      <td>0.836102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.711771</td>\n",
       "      <td>0.625738</td>\n",
       "      <td>20</td>\n",
       "      <td>0.106436</td>\n",
       "      <td>86</td>\n",
       "      <td>493</td>\n",
       "      <td>772</td>\n",
       "      <td>961</td>\n",
       "      <td>0.166852</td>\n",
       "      <td>0.536372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.456682</td>\n",
       "      <td>0.451429</td>\n",
       "      <td>491</td>\n",
       "      <td>0.187445</td>\n",
       "      <td>70</td>\n",
       "      <td>621</td>\n",
       "      <td>585</td>\n",
       "      <td>712</td>\n",
       "      <td>0.171147</td>\n",
       "      <td>0.410388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.543850</td>\n",
       "      <td>0.426447</td>\n",
       "      <td>189</td>\n",
       "      <td>0.201176</td>\n",
       "      <td>13</td>\n",
       "      <td>580</td>\n",
       "      <td>578</td>\n",
       "      <td>576</td>\n",
       "      <td>0.171205</td>\n",
       "      <td>0.491564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.647272</td>\n",
       "      <td>0.509298</td>\n",
       "      <td>251</td>\n",
       "      <td>0.237333</td>\n",
       "      <td>11</td>\n",
       "      <td>446</td>\n",
       "      <td>824</td>\n",
       "      <td>281</td>\n",
       "      <td>0.169666</td>\n",
       "      <td>0.673658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.926680</td>\n",
       "      <td>0.478350</td>\n",
       "      <td>121</td>\n",
       "      <td>0.298567</td>\n",
       "      <td>62</td>\n",
       "      <td>449</td>\n",
       "      <td>575</td>\n",
       "      <td>949</td>\n",
       "      <td>0.170741</td>\n",
       "      <td>0.782413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     colsample_bylevel  colsample_bytree  epoch  learning_rate  max_depth  \\\n",
       "180           0.654386          0.921381    181       0.043654         50   \n",
       "152           0.702562          0.529863    153       0.045601         51   \n",
       "343           0.453020          0.535704    344       0.055449         43   \n",
       "228           0.901923          0.925929    229       0.076780         30   \n",
       "313           0.971499          0.814491    314       0.098614         82   \n",
       "19            0.711771          0.625738     20       0.106436         86   \n",
       "490           0.456682          0.451429    491       0.187445         70   \n",
       "188           0.543850          0.426447    189       0.201176         13   \n",
       "250           0.647272          0.509298    251       0.237333         11   \n",
       "120           0.926680          0.478350    121       0.298567         62   \n",
       "\n",
       "     min_child_samples  n_estimators  num_leaves     score  subsample  \n",
       "180                495           569         348  0.170261   0.936950  \n",
       "152                431           572         126  0.167844   0.860284  \n",
       "343                288           814         634  0.163962   0.943352  \n",
       "228                747           896         730  0.171047   0.569215  \n",
       "313                416           293         568  0.167425   0.836102  \n",
       "19                 493           772         961  0.166852   0.536372  \n",
       "490                621           585         712  0.171147   0.410388  \n",
       "188                580           578         576  0.171205   0.491564  \n",
       "250                446           824         281  0.169666   0.673658  \n",
       "120                449           575         949  0.170741   0.782413  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_tuning_df.head(10).sort_values('learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상위 10개를 확인 후 대략적으로 좁혀진 파라미터 범위를 기반으로 Finer Search 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = {\n",
    "    'n_estimators': [500, 900],\n",
    "    'max_depth': [30, 90],\n",
    "    'learning_rate': [0, 2],\n",
    "    'subsample': [0.5, 1],\n",
    "    'colsample_bylevel': [0.45, 1],\n",
    "    'colsample_bytree': [0.4, 0.9],\n",
    "    'num_leaves': [300, 1000],\n",
    "    'min_child_samples': [300, 800],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\t\t\t\t 17:25:36\n",
      "1 epoch is now calculating . . .\t 17:25:40\n",
      "50 epoch is now calculating . . .\t 17:29:24\n",
      "100 epoch is now calculating . . .\t 17:33:18\n",
      "150 epoch is now calculating . . .\t 17:37:13\n",
      "200 epoch is now calculating . . .\t 17:41:15\n",
      "250 epoch is now calculating . . .\t 17:45:06\n",
      "300 epoch is now calculating . . .\t 17:49:02\n",
      "All Coarse Searching is Finished\n",
      "time duration: 0:23:25\n",
      "(300, 10)\n"
     ]
    }
   ],
   "source": [
    "lgbm_finer_df = FinerSearch(train, label, param_range, 'lgbm', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.688960</td>\n",
       "      <td>0.598889</td>\n",
       "      <td>39</td>\n",
       "      <td>0.050034</td>\n",
       "      <td>82</td>\n",
       "      <td>310</td>\n",
       "      <td>711</td>\n",
       "      <td>989</td>\n",
       "      <td>0.164657</td>\n",
       "      <td>0.879480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.809189</td>\n",
       "      <td>0.576079</td>\n",
       "      <td>45</td>\n",
       "      <td>0.035605</td>\n",
       "      <td>40</td>\n",
       "      <td>312</td>\n",
       "      <td>887</td>\n",
       "      <td>655</td>\n",
       "      <td>0.164780</td>\n",
       "      <td>0.643502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.890466</td>\n",
       "      <td>0.665797</td>\n",
       "      <td>56</td>\n",
       "      <td>0.047123</td>\n",
       "      <td>72</td>\n",
       "      <td>309</td>\n",
       "      <td>715</td>\n",
       "      <td>728</td>\n",
       "      <td>0.164784</td>\n",
       "      <td>0.569443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.588493</td>\n",
       "      <td>0.524845</td>\n",
       "      <td>50</td>\n",
       "      <td>0.050481</td>\n",
       "      <td>32</td>\n",
       "      <td>340</td>\n",
       "      <td>761</td>\n",
       "      <td>472</td>\n",
       "      <td>0.165075</td>\n",
       "      <td>0.513969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.798097</td>\n",
       "      <td>0.576222</td>\n",
       "      <td>181</td>\n",
       "      <td>0.084062</td>\n",
       "      <td>69</td>\n",
       "      <td>333</td>\n",
       "      <td>500</td>\n",
       "      <td>766</td>\n",
       "      <td>0.165193</td>\n",
       "      <td>0.660387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.808857</td>\n",
       "      <td>0.451993</td>\n",
       "      <td>93</td>\n",
       "      <td>0.071855</td>\n",
       "      <td>52</td>\n",
       "      <td>417</td>\n",
       "      <td>867</td>\n",
       "      <td>369</td>\n",
       "      <td>0.165211</td>\n",
       "      <td>0.546055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.666552</td>\n",
       "      <td>0.474292</td>\n",
       "      <td>14</td>\n",
       "      <td>0.067878</td>\n",
       "      <td>88</td>\n",
       "      <td>402</td>\n",
       "      <td>827</td>\n",
       "      <td>990</td>\n",
       "      <td>0.165275</td>\n",
       "      <td>0.846135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.777473</td>\n",
       "      <td>0.767652</td>\n",
       "      <td>256</td>\n",
       "      <td>0.082195</td>\n",
       "      <td>64</td>\n",
       "      <td>318</td>\n",
       "      <td>552</td>\n",
       "      <td>986</td>\n",
       "      <td>0.165422</td>\n",
       "      <td>0.851954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.663936</td>\n",
       "      <td>73</td>\n",
       "      <td>0.056838</td>\n",
       "      <td>88</td>\n",
       "      <td>410</td>\n",
       "      <td>889</td>\n",
       "      <td>680</td>\n",
       "      <td>0.165542</td>\n",
       "      <td>0.671157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.716990</td>\n",
       "      <td>0.448110</td>\n",
       "      <td>276</td>\n",
       "      <td>0.119619</td>\n",
       "      <td>42</td>\n",
       "      <td>314</td>\n",
       "      <td>714</td>\n",
       "      <td>344</td>\n",
       "      <td>0.165626</td>\n",
       "      <td>0.588893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     colsample_bylevel  colsample_bytree  epoch  learning_rate  max_depth  \\\n",
       "38            0.688960          0.598889     39       0.050034         82   \n",
       "44            0.809189          0.576079     45       0.035605         40   \n",
       "55            0.890466          0.665797     56       0.047123         72   \n",
       "49            0.588493          0.524845     50       0.050481         32   \n",
       "180           0.798097          0.576222    181       0.084062         69   \n",
       "92            0.808857          0.451993     93       0.071855         52   \n",
       "13            0.666552          0.474292     14       0.067878         88   \n",
       "255           0.777473          0.767652    256       0.082195         64   \n",
       "72            0.791209          0.663936     73       0.056838         88   \n",
       "275           0.716990          0.448110    276       0.119619         42   \n",
       "\n",
       "     min_child_samples  n_estimators  num_leaves     score  subsample  \n",
       "38                 310           711         989  0.164657   0.879480  \n",
       "44                 312           887         655  0.164780   0.643502  \n",
       "55                 309           715         728  0.164784   0.569443  \n",
       "49                 340           761         472  0.165075   0.513969  \n",
       "180                333           500         766  0.165193   0.660387  \n",
       "92                 417           867         369  0.165211   0.546055  \n",
       "13                 402           827         990  0.165275   0.846135  \n",
       "255                318           552         986  0.165422   0.851954  \n",
       "72                 410           889         680  0.165542   0.671157  \n",
       "275                314           714         344  0.165626   0.588893  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_finer_df.head(10)#.sort_values('max_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제출해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'n_estimators': 711,\n",
    "    'max_depth': 82,\n",
    "    'learning_rate': 0.050034,\n",
    "    'subsample': 0.879480,\n",
    "    'colsample_bylevel': 0.688960,\n",
    "    'colsample_bytree': 0.598889,\n",
    "    'num_leaves': 989,\n",
    "    'min_child_samples': 310,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tun = LGBMRegressor(n_estimators=711,\n",
    "                         max_depth=82,\n",
    "                         learning_rate=0.050034,\n",
    "                         subsample=0.879480,\n",
    "                         colsample_bylevel=0.688960,\n",
    "                         colsample_bytree=0.598889,\n",
    "                         num_leaves=989,\n",
    "                         min_child_samples=310)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "y_pred = lgbm_tun.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.expm1(y_pred), np.expm1(y_test)))\n",
    "\n",
    "X_sub = test[features]\n",
    "\n",
    "lgbm_tun.fit(train, label)\n",
    "y_pred = lgbm_tun.predict(X_sub)\n",
    "y_pred\n",
    "\n",
    "submission = LetSubmit(np.expm1(y_pred), \"six_lgbm_tuning\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110716.45541102542"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "y_pred = lgbm_tun.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.expm1(y_pred), np.expm1(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.1560804 , 13.07160478, 14.23687242, ..., 13.05612279,\n",
       "       12.61816677, 13.00301265])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_tun.fit(train, label)\n",
    "y_pred = lgbm_tun.predict(X_sub)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>4.942906e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>4.744508e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>1.256917e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>3.068664e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>2.861011e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  15035  4.942906e+05\n",
       "1  15036  4.744508e+05\n",
       "2  15037  1.256917e+06\n",
       "3  15038  3.068664e+05\n",
       "4  15039  2.861011e+05"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = LetSubmit(np.expm1(y_pred), \"six_lgbm_coarse\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Submission 결과 : 129199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 음.. 좋지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV - `LightGBM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 Coarse / Finer Search 의 결과가 좋지 않았으므로 일단 GridSearch를 진행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=5)]: Done 500 out of 500 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [200, 500, 800, 1000],\n",
    "    'max_depth': [10, 30, 50, 80, 100],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.5, 1],\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "grid_lgbm, params_df, rmsle = BestParamsGrid(lgbm, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200} \tRMSE: 0.1618\n",
      "2: {'learning_rate': 0.1, 'max_depth': 30, 'n_estimators': 200} \tRMSE: 0.162\n",
      "3: {'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 200} \tRMSE: 0.162\n",
      "4: {'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 200} \tRMSE: 0.162\n",
      "5: {'learning_rate': 0.1, 'max_depth': 80, 'n_estimators': 200} \tRMSE: 0.162\n",
      "6: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500} \tRMSE: 0.162\n",
      "7: {'learning_rate': 0.1, 'max_depth': 30, 'n_estimators': 500} \tRMSE: 0.1623\n",
      "8: {'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 500} \tRMSE: 0.1623\n",
      "9: {'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 500} \tRMSE: 0.1623\n",
      "10: {'learning_rate': 0.1, 'max_depth': 80, 'n_estimators': 500} \tRMSE: 0.1623\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_lgbm.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- learning rate 가 0.1로 고정되어있으므로 learning rate를 좀 더 variance 하게 주는 것을 중심으로 다시 Grid Serach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=5)]: Done 400 out of 400 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'max_depth': [10, 20, 30, 50],\n",
    "    'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.12],\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "grid_lgbm, params_df, rmsle = BestParamsGrid(lgbm, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 500} \tRMSE: 0.161\n",
      "2: {'learning_rate': 0.08, 'max_depth': 20, 'n_estimators': 400} \tRMSE: 0.1613\n",
      "3: {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 400} \tRMSE: 0.1614\n",
      "4: {'learning_rate': 0.08, 'max_depth': 50, 'n_estimators': 400} \tRMSE: 0.1614\n",
      "5: {'learning_rate': 0.08, 'max_depth': 30, 'n_estimators': 400} \tRMSE: 0.1614\n",
      "6: {'learning_rate': 0.08, 'max_depth': 20, 'n_estimators': 300} \tRMSE: 0.1614\n",
      "7: {'learning_rate': 0.08, 'max_depth': 50, 'n_estimators': 300} \tRMSE: 0.1614\n",
      "8: {'learning_rate': 0.08, 'max_depth': 30, 'n_estimators': 300} \tRMSE: 0.1614\n",
      "9: {'learning_rate': 0.05, 'max_depth': 50, 'n_estimators': 500} \tRMSE: 0.1614\n",
      "10: {'learning_rate': 0.05, 'max_depth': 30, 'n_estimators': 500} \tRMSE: 0.1614\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_lgbm.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=5)]: Done 1003 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=5)]: Done 1448 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=5)]: Done 1800 out of 1800 | elapsed:  8.0min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [300, 350, 400, 450, 500],\n",
    "    'max_depth': [10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "    'learning_rate': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "grid_lgbm, params_df, rmsle = BestParamsGrid(lgbm, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.06, 'max_depth': 15, 'n_estimators': 500} \tRMSE: 0.1608\n",
      "2: {'learning_rate': 0.06, 'max_depth': 15, 'n_estimators': 450} \tRMSE: 0.1608\n",
      "3: {'learning_rate': 0.06, 'max_depth': 20, 'n_estimators': 500} \tRMSE: 0.1609\n",
      "4: {'learning_rate': 0.06, 'max_depth': 50, 'n_estimators': 500} \tRMSE: 0.1609\n",
      "5: {'learning_rate': 0.06, 'max_depth': 35, 'n_estimators': 500} \tRMSE: 0.1609\n",
      "6: {'learning_rate': 0.06, 'max_depth': 25, 'n_estimators': 500} \tRMSE: 0.1609\n",
      "7: {'learning_rate': 0.06, 'max_depth': 40, 'n_estimators': 500} \tRMSE: 0.1609\n",
      "8: {'learning_rate': 0.06, 'max_depth': 45, 'n_estimators': 500} \tRMSE: 0.1609\n",
      "9: {'learning_rate': 0.06, 'max_depth': 30, 'n_estimators': 500} \tRMSE: 0.1609\n",
      "10: {'learning_rate': 0.06, 'max_depth': 15, 'n_estimators': 400} \tRMSE: 0.161\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_lgbm.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- learning rate 는 0.06이 최적인 것 같아 보인다. \n",
    "\n",
    "\n",
    "- 나머지 파라미터 (max_depth, n_estimators) 를 변화를 주면서 Finer Search 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\t\t\t\t 21:10:48\n",
      "1 epoch is now calculating . . .\t 21:10:51\n",
      "10 epoch is now calculating . . .\t 21:11:10\n",
      "20 epoch is now calculating . . .\t 21:11:32\n",
      "30 epoch is now calculating . . .\t 21:11:55\n",
      "40 epoch is now calculating . . .\t 21:12:17\n",
      "50 epoch is now calculating . . .\t 21:12:40\n",
      "60 epoch is now calculating . . .\t 21:13:02\n",
      "70 epoch is now calculating . . .\t 21:13:25\n",
      "80 epoch is now calculating . . .\t 21:13:47\n",
      "90 epoch is now calculating . . .\t 21:14:10\n",
      "100 epoch is now calculating . . .\t 21:14:32\n",
      "All Coarse Searching is Finished\n",
      "time duration: 0:03:44\n",
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [450, 550],\n",
    "    'max_depth': [15, 40],\n",
    "    'learning_rate': [0.055, 0.065],\n",
    "}\n",
    "\n",
    "lgbm_finer = FinerSearch(train, label, param_grid, 'lgbm', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.400000</td>\n",
       "      <td>0.057212</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>485.200000</td>\n",
       "      <td>0.159846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.869618</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>1.269296</td>\n",
       "      <td>16.198765</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.055727</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>0.159749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.250000</td>\n",
       "      <td>0.056004</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>483.500000</td>\n",
       "      <td>0.159780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.056487</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>491.500000</td>\n",
       "      <td>0.159845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.058558</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>495.750000</td>\n",
       "      <td>0.159917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.059654</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>0.159927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           epoch  learning_rate  max_depth  n_estimators      score\n",
       "count  10.000000      10.000000  10.000000     10.000000  10.000000\n",
       "mean   54.400000       0.057212  16.500000    485.200000   0.159846\n",
       "std    30.869618       0.001455   1.269296     16.198765   0.000075\n",
       "min     5.000000       0.055727  15.000000    450.000000   0.159749\n",
       "25%    32.250000       0.056004  16.000000    483.500000   0.159780\n",
       "50%    49.000000       0.056487  16.000000    491.500000   0.159845\n",
       "75%    83.000000       0.058558  17.000000    495.750000   0.159917\n",
       "max    97.000000       0.059654  19.000000    499.000000   0.159927"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_finer.head(10).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOW! `0.159749`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- score가 0.159대로 떨어졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 나머지 parameter도 최적화를 진행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] col_bylevel: 0.7, col_bytree: 0.7, m_c_s: 50, num_l: 300, subsm: 0.5 \t\tRMSE: 0.1618\n",
      "[2] col_bylevel: 1, col_bytree: 0.7, m_c_s: 50, num_l: 300, subsm: 0.5 \t\tRMSE: 0.1618\n",
      "[3] col_bylevel: 1, col_bytree: 0.7, m_c_s: 50, num_l: 300, subsm: 0.8 \t\tRMSE: 0.1618\n",
      "[4] col_bylevel: 1, col_bytree: 0.7, m_c_s: 50, num_l: 300, subsm: 1 \t\tRMSE: 0.1618\n",
      "[5] col_bylevel: 1, col_bytree: 0.7, m_c_s: 50, num_l: 500, subsm: 0.5 \t\tRMSE: 0.1618\n",
      "[6] col_bylevel: 1, col_bytree: 0.7, m_c_s: 50, num_l: 500, subsm: 0.8 \t\tRMSE: 0.1618\n",
      "[7] col_bylevel: 1, col_bytree: 0.7, m_c_s: 50, num_l: 500, subsm: 1 \t\tRMSE: 0.1618\n",
      "[8] col_bylevel: 1, col_bytree: 0.7, m_c_s: 50, num_l: 800, subsm: 0.5 \t\tRMSE: 0.1618\n",
      "[9] col_bylevel: 1, col_bytree: 0.7, m_c_s: 50, num_l: 800, subsm: 0.8 \t\tRMSE: 0.1618\n",
      "[10] col_bylevel: 1, col_bytree: 0.7, m_c_s: 50, num_l: 800, subsm: 1 \t\tRMSE: 0.1618\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_lgbm.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    colsample_bylevel = results.loc[i]['params']['colsample_bylevel']\n",
    "    colsample_bytree = results.loc[i]['params']['colsample_bytree']\n",
    "    min_child_samples = results.loc[i]['params']['min_child_samples']\n",
    "    num_leaves = results.loc[i]['params']['num_leaves']\n",
    "    subsample = results.loc[i]['params']['subsample']\n",
    "    print(\"[{}] col_bylevel: {}, col_bytree: {}, m_c_s: {}, num_l: {}, subsm: {}\".format(i+1, \\\n",
    "                                                                                         colsample_bylevel, \\\n",
    "                                                                                         colsample_bytree, \\\n",
    "                                                                                         min_child_samples, \\\n",
    "                                                                                         num_leaves, \\\n",
    "                                                                                         subsample), \\\n",
    "          \"\\t\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\t\t\t\t 21:52:27\n",
      "1 epoch is now calculating . . .\t 0:00:04\n",
      "30 epoch is now calculating . . .\t 0:02:07\n",
      "60 epoch is now calculating . . .\t 0:04:09\n",
      "90 epoch is now calculating . . .\t 0:06:30\n",
      "120 epoch is now calculating . . .\t 0:08:39\n",
      "150 epoch is now calculating . . .\t 0:10:53\n",
      "180 epoch is now calculating . . .\t 0:13:05\n",
      "210 epoch is now calculating . . .\t 0:15:20\n",
      "240 epoch is now calculating . . .\t 0:17:27\n",
      "270 epoch is now calculating . . .\t 0:19:48\n",
      "300 epoch is now calculating . . .\t 0:22:18\n",
      "All Coarse Searching is Finished\n",
      "time duration: 0:22:18\n",
      "(300, 10)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [450, 499],\n",
    "    'max_depth': [15, 19],\n",
    "    'learning_rate': [0.0557, 0.0596],\n",
    "    'subsample': [0.5, 1],\n",
    "    'colsample_bylevel': [0.7, 1],\n",
    "    'colsample_bytree': [0.6, 0.8],\n",
    "    'num_leaves': [300, 500],\n",
    "    'min_child_samples': [10, 100],\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm_finer_2 = FinerSearch(train, label, param_grid, 'lgbm', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.883418</td>\n",
       "      <td>0.675169</td>\n",
       "      <td>156.900000</td>\n",
       "      <td>0.057366</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>81.800000</td>\n",
       "      <td>465.800000</td>\n",
       "      <td>423.10000</td>\n",
       "      <td>0.159904</td>\n",
       "      <td>0.756813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.051347</td>\n",
       "      <td>0.058778</td>\n",
       "      <td>72.130206</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>1.074968</td>\n",
       "      <td>4.709329</td>\n",
       "      <td>11.516172</td>\n",
       "      <td>43.11857</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.150676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.810936</td>\n",
       "      <td>0.605996</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>362.00000</td>\n",
       "      <td>0.159660</td>\n",
       "      <td>0.511139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.832726</td>\n",
       "      <td>0.623305</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>0.056313</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>457.500000</td>\n",
       "      <td>393.25000</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.653925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.895476</td>\n",
       "      <td>0.665913</td>\n",
       "      <td>165.500000</td>\n",
       "      <td>0.057125</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>412.00000</td>\n",
       "      <td>0.159931</td>\n",
       "      <td>0.780676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.921700</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>187.250000</td>\n",
       "      <td>0.058512</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>468.250000</td>\n",
       "      <td>447.25000</td>\n",
       "      <td>0.159962</td>\n",
       "      <td>0.862330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.939318</td>\n",
       "      <td>0.768216</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>0.059222</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>491.00000</td>\n",
       "      <td>0.160005</td>\n",
       "      <td>0.970658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       colsample_bylevel  colsample_bytree       epoch  learning_rate  \\\n",
       "count          10.000000         10.000000   10.000000      10.000000   \n",
       "mean            0.883418          0.675169  156.900000       0.057366   \n",
       "std             0.051347          0.058778   72.130206       0.001321   \n",
       "min             0.810936          0.605996   50.000000       0.055803   \n",
       "25%             0.832726          0.623305  103.750000       0.056313   \n",
       "50%             0.895476          0.665913  165.500000       0.057125   \n",
       "75%             0.921700          0.723228  187.250000       0.058512   \n",
       "max             0.939318          0.768216  293.000000       0.059222   \n",
       "\n",
       "       max_depth  min_child_samples  n_estimators  num_leaves      score  \\\n",
       "count  10.000000          10.000000     10.000000    10.00000  10.000000   \n",
       "mean   15.600000          81.800000    465.800000   423.10000   0.159904   \n",
       "std     1.074968           4.709329     11.516172    43.11857   0.000101   \n",
       "min    15.000000          73.000000    453.000000   362.00000   0.159660   \n",
       "25%    15.000000          78.500000    457.500000   393.25000   0.159877   \n",
       "50%    15.000000          82.000000    464.000000   412.00000   0.159931   \n",
       "75%    15.750000          85.500000    468.250000   447.25000   0.159962   \n",
       "max    18.000000          88.000000    491.000000   491.00000   0.160005   \n",
       "\n",
       "       subsample  \n",
       "count  10.000000  \n",
       "mean    0.756813  \n",
       "std     0.150676  \n",
       "min     0.511139  \n",
       "25%     0.653925  \n",
       "50%     0.780676  \n",
       "75%     0.862330  \n",
       "max     0.970658  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_finer_2.head(10).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\t\t\t\t 22:18:46\n",
      "1 epoch is now calculating . . .\t 0:00:03\n",
      "10 epoch is now calculating . . .\t 0:00:31\n",
      "20 epoch is now calculating . . .\t 0:01:06\n",
      "30 epoch is now calculating . . .\t 0:01:38\n",
      "40 epoch is now calculating . . .\t 0:02:10\n",
      "50 epoch is now calculating . . .\t 0:02:41\n",
      "60 epoch is now calculating . . .\t 0:03:12\n",
      "70 epoch is now calculating . . .\t 0:03:44\n",
      "80 epoch is now calculating . . .\t 0:04:16\n",
      "90 epoch is now calculating . . .\t 0:04:49\n",
      "100 epoch is now calculating . . .\t 0:05:21\n",
      "All Coarse Searching is Finished\n",
      "time duration: 0:05:21\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [450, 490],\n",
    "    'max_depth': [15, 17],\n",
    "    'learning_rate': [0.0558, 0.0592],\n",
    "    'subsample': [0.5, 1],\n",
    "    'colsample_bylevel': [0.8109, 0.9393],\n",
    "    'colsample_bytree': [0.6060, 0.7682],\n",
    "    'num_leaves': [350, 490],\n",
    "    'min_child_samples': [70, 90],\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm_finer_3 = FinerSearch(train, label, param_grid, 'lgbm', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.886023</td>\n",
       "      <td>0.641096</td>\n",
       "      <td>36.700000</td>\n",
       "      <td>0.057053</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>83.100000</td>\n",
       "      <td>465.900000</td>\n",
       "      <td>406.100000</td>\n",
       "      <td>0.159846</td>\n",
       "      <td>0.786443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032775</td>\n",
       "      <td>0.047574</td>\n",
       "      <td>22.430386</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>5.858517</td>\n",
       "      <td>12.591443</td>\n",
       "      <td>38.999858</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.151209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.838117</td>\n",
       "      <td>0.606442</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.056098</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.159776</td>\n",
       "      <td>0.543293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.857084</td>\n",
       "      <td>0.614128</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>0.056284</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>381.500000</td>\n",
       "      <td>0.159836</td>\n",
       "      <td>0.657393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.888125</td>\n",
       "      <td>0.622290</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.057348</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>463.500000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>0.159843</td>\n",
       "      <td>0.846149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.918066</td>\n",
       "      <td>0.628536</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.057599</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>0.159864</td>\n",
       "      <td>0.870474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.925448</td>\n",
       "      <td>0.737596</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.057922</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>0.159892</td>\n",
       "      <td>0.969138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       colsample_bylevel  colsample_bytree      epoch  learning_rate  \\\n",
       "count          10.000000         10.000000  10.000000      10.000000   \n",
       "mean            0.886023          0.641096  36.700000       0.057053   \n",
       "std             0.032775          0.047574  22.430386       0.000719   \n",
       "min             0.838117          0.606442  10.000000       0.056098   \n",
       "25%             0.857084          0.614128  18.750000       0.056284   \n",
       "50%             0.888125          0.622290  29.000000       0.057348   \n",
       "75%             0.918066          0.628536  59.000000       0.057599   \n",
       "max             0.925448          0.737596  68.000000       0.057922   \n",
       "\n",
       "       max_depth  min_child_samples  n_estimators  num_leaves      score  \\\n",
       "count  10.000000          10.000000     10.000000   10.000000  10.000000   \n",
       "mean   15.300000          83.100000    465.900000  406.100000   0.159846   \n",
       "std     0.483046           5.858517     12.591443   38.999858   0.000034   \n",
       "min    15.000000          74.000000    450.000000  359.000000   0.159776   \n",
       "25%    15.000000          78.000000    455.000000  381.500000   0.159836   \n",
       "50%    15.000000          85.000000    463.500000  399.000000   0.159843   \n",
       "75%    15.750000          87.500000    477.000000  413.000000   0.159864   \n",
       "max    16.000000          89.000000    484.000000  476.000000   0.159892   \n",
       "\n",
       "       subsample  \n",
       "count  10.000000  \n",
       "mean    0.786443  \n",
       "std     0.151209  \n",
       "min     0.543293  \n",
       "25%     0.657393  \n",
       "50%     0.846149  \n",
       "75%     0.870474  \n",
       "max     0.969138  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_finer_3.head(10).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\t\t\t\t 22:27:50\n",
      "1 epoch is now calculating . . .\t 0:00:02\n",
      "10 epoch is now calculating . . .\t 0:00:28\n",
      "20 epoch is now calculating . . .\t 0:00:57\n",
      "30 epoch is now calculating . . .\t 0:01:26\n",
      "40 epoch is now calculating . . .\t 0:01:56\n",
      "50 epoch is now calculating . . .\t 0:02:26\n",
      "60 epoch is now calculating . . .\t 0:02:56\n",
      "70 epoch is now calculating . . .\t 0:03:26\n",
      "80 epoch is now calculating . . .\t 0:03:57\n",
      "90 epoch is now calculating . . .\t 0:04:27\n",
      "100 epoch is now calculating . . .\t 0:04:57\n",
      "All Coarse Searching is Finished\n",
      "time duration: 0:04:57\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [450, 480],\n",
    "    'max_depth': [15, 16],\n",
    "    'learning_rate': [0.056, 0.0579],\n",
    "    'subsample': [0.54, 0.97],\n",
    "    'colsample_bylevel': [0.838, 0.925],\n",
    "    'colsample_bytree': [0.6064, 0.737],\n",
    "    'num_leaves': [350, 480],\n",
    "    'min_child_samples': [74, 89],\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm_finer_4 = FinerSearch(train, label, param_grid, 'lgbm', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.918582</td>\n",
       "      <td>0.626395</td>\n",
       "      <td>39</td>\n",
       "      <td>0.057606</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>465</td>\n",
       "      <td>465</td>\n",
       "      <td>0.159645</td>\n",
       "      <td>0.960575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.885215</td>\n",
       "      <td>0.611295</td>\n",
       "      <td>99</td>\n",
       "      <td>0.056405</td>\n",
       "      <td>15</td>\n",
       "      <td>78</td>\n",
       "      <td>461</td>\n",
       "      <td>458</td>\n",
       "      <td>0.159659</td>\n",
       "      <td>0.753503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.889167</td>\n",
       "      <td>0.616803</td>\n",
       "      <td>92</td>\n",
       "      <td>0.057896</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>468</td>\n",
       "      <td>389</td>\n",
       "      <td>0.159661</td>\n",
       "      <td>0.860150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.667957</td>\n",
       "      <td>81</td>\n",
       "      <td>0.057171</td>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "      <td>468</td>\n",
       "      <td>462</td>\n",
       "      <td>0.159723</td>\n",
       "      <td>0.911559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.864528</td>\n",
       "      <td>0.630756</td>\n",
       "      <td>68</td>\n",
       "      <td>0.056741</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>450</td>\n",
       "      <td>464</td>\n",
       "      <td>0.159756</td>\n",
       "      <td>0.817356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.894323</td>\n",
       "      <td>0.615414</td>\n",
       "      <td>51</td>\n",
       "      <td>0.056543</td>\n",
       "      <td>15</td>\n",
       "      <td>77</td>\n",
       "      <td>463</td>\n",
       "      <td>441</td>\n",
       "      <td>0.159766</td>\n",
       "      <td>0.929069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.902519</td>\n",
       "      <td>0.633855</td>\n",
       "      <td>96</td>\n",
       "      <td>0.056623</td>\n",
       "      <td>15</td>\n",
       "      <td>87</td>\n",
       "      <td>476</td>\n",
       "      <td>455</td>\n",
       "      <td>0.159796</td>\n",
       "      <td>0.923251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.920799</td>\n",
       "      <td>0.615419</td>\n",
       "      <td>65</td>\n",
       "      <td>0.057857</td>\n",
       "      <td>15</td>\n",
       "      <td>88</td>\n",
       "      <td>469</td>\n",
       "      <td>366</td>\n",
       "      <td>0.159810</td>\n",
       "      <td>0.699336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.908884</td>\n",
       "      <td>0.723677</td>\n",
       "      <td>46</td>\n",
       "      <td>0.056880</td>\n",
       "      <td>15</td>\n",
       "      <td>86</td>\n",
       "      <td>472</td>\n",
       "      <td>381</td>\n",
       "      <td>0.159820</td>\n",
       "      <td>0.726196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.904931</td>\n",
       "      <td>0.680647</td>\n",
       "      <td>60</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>450</td>\n",
       "      <td>374</td>\n",
       "      <td>0.159831</td>\n",
       "      <td>0.717830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bylevel  colsample_bytree  epoch  learning_rate  max_depth  \\\n",
       "38           0.918582          0.626395     39       0.057606         15   \n",
       "98           0.885215          0.611295     99       0.056405         15   \n",
       "91           0.889167          0.616803     92       0.057896         15   \n",
       "80           0.864706          0.667957     81       0.057171         15   \n",
       "67           0.864528          0.630756     68       0.056741         15   \n",
       "50           0.894323          0.615414     51       0.056543         15   \n",
       "95           0.902519          0.633855     96       0.056623         15   \n",
       "64           0.920799          0.615419     65       0.057857         15   \n",
       "45           0.908884          0.723677     46       0.056880         15   \n",
       "59           0.904931          0.680647     60       0.057292         15   \n",
       "\n",
       "    min_child_samples  n_estimators  num_leaves     score  subsample  \n",
       "38                 83           465         465  0.159645   0.960575  \n",
       "98                 78           461         458  0.159659   0.753503  \n",
       "91                 76           468         389  0.159661   0.860150  \n",
       "80                 74           468         462  0.159723   0.911559  \n",
       "67                 83           450         464  0.159756   0.817356  \n",
       "50                 77           463         441  0.159766   0.929069  \n",
       "95                 87           476         455  0.159796   0.923251  \n",
       "64                 88           469         366  0.159810   0.699336  \n",
       "45                 86           472         381  0.159820   0.726196  \n",
       "59                 83           450         374  0.159831   0.717830  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_finer_4.head(10)#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\t\t\t\t 22:37:18\n",
      "1 epoch is now calculating . . .\t 0:00:03\n",
      "10 epoch is now calculating . . .\t 0:00:29\n",
      "20 epoch is now calculating . . .\t 0:01:00\n",
      "30 epoch is now calculating . . .\t 0:01:31\n",
      "40 epoch is now calculating . . .\t 0:02:03\n",
      "50 epoch is now calculating . . .\t 0:02:35\n",
      "60 epoch is now calculating . . .\t 0:03:06\n",
      "70 epoch is now calculating . . .\t 0:03:38\n",
      "80 epoch is now calculating . . .\t 0:04:10\n",
      "90 epoch is now calculating . . .\t 0:04:42\n",
      "100 epoch is now calculating . . .\t 0:05:13\n",
      "All Coarse Searching is Finished\n",
      "time duration: 0:05:13\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [450, 476],\n",
    "    'max_depth': [15, 19],\n",
    "    'learning_rate': [0.056, 0.0579],\n",
    "    'subsample': [0.7, 0.96],\n",
    "    'colsample_bylevel': [0.86, 0.92],\n",
    "    'colsample_bytree': [0.61, 0.72],\n",
    "    'num_leaves': [366, 465],\n",
    "    'min_child_samples': [74, 88],\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm_finer_5 = FinerSearch(train, label, param_grid, 'lgbm', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.883408</td>\n",
       "      <td>0.680897</td>\n",
       "      <td>78</td>\n",
       "      <td>0.056331</td>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "      <td>452</td>\n",
       "      <td>425</td>\n",
       "      <td>0.159735</td>\n",
       "      <td>0.820913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861548</td>\n",
       "      <td>0.610949</td>\n",
       "      <td>4</td>\n",
       "      <td>0.056137</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>463</td>\n",
       "      <td>404</td>\n",
       "      <td>0.159740</td>\n",
       "      <td>0.713915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.901237</td>\n",
       "      <td>0.697109</td>\n",
       "      <td>73</td>\n",
       "      <td>0.056988</td>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "      <td>466</td>\n",
       "      <td>464</td>\n",
       "      <td>0.159811</td>\n",
       "      <td>0.871708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.884681</td>\n",
       "      <td>0.650134</td>\n",
       "      <td>36</td>\n",
       "      <td>0.056007</td>\n",
       "      <td>15</td>\n",
       "      <td>82</td>\n",
       "      <td>454</td>\n",
       "      <td>417</td>\n",
       "      <td>0.159820</td>\n",
       "      <td>0.771452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.869893</td>\n",
       "      <td>0.670911</td>\n",
       "      <td>97</td>\n",
       "      <td>0.056878</td>\n",
       "      <td>16</td>\n",
       "      <td>86</td>\n",
       "      <td>462</td>\n",
       "      <td>403</td>\n",
       "      <td>0.159855</td>\n",
       "      <td>0.935893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.874411</td>\n",
       "      <td>0.629861</td>\n",
       "      <td>61</td>\n",
       "      <td>0.057430</td>\n",
       "      <td>17</td>\n",
       "      <td>87</td>\n",
       "      <td>454</td>\n",
       "      <td>428</td>\n",
       "      <td>0.159859</td>\n",
       "      <td>0.925825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.917199</td>\n",
       "      <td>0.620533</td>\n",
       "      <td>20</td>\n",
       "      <td>0.057452</td>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "      <td>467</td>\n",
       "      <td>453</td>\n",
       "      <td>0.159890</td>\n",
       "      <td>0.747736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.860472</td>\n",
       "      <td>0.684594</td>\n",
       "      <td>89</td>\n",
       "      <td>0.057091</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "      <td>451</td>\n",
       "      <td>408</td>\n",
       "      <td>0.159899</td>\n",
       "      <td>0.950582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.911315</td>\n",
       "      <td>0.698385</td>\n",
       "      <td>41</td>\n",
       "      <td>0.056582</td>\n",
       "      <td>15</td>\n",
       "      <td>82</td>\n",
       "      <td>458</td>\n",
       "      <td>376</td>\n",
       "      <td>0.159928</td>\n",
       "      <td>0.807325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.907082</td>\n",
       "      <td>0.615837</td>\n",
       "      <td>5</td>\n",
       "      <td>0.056589</td>\n",
       "      <td>16</td>\n",
       "      <td>80</td>\n",
       "      <td>453</td>\n",
       "      <td>384</td>\n",
       "      <td>0.159930</td>\n",
       "      <td>0.824228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bylevel  colsample_bytree  epoch  learning_rate  max_depth  \\\n",
       "77           0.883408          0.680897     78       0.056331         15   \n",
       "3            0.861548          0.610949      4       0.056137         15   \n",
       "72           0.901237          0.697109     73       0.056988         15   \n",
       "35           0.884681          0.650134     36       0.056007         15   \n",
       "96           0.869893          0.670911     97       0.056878         16   \n",
       "60           0.874411          0.629861     61       0.057430         17   \n",
       "19           0.917199          0.620533     20       0.057452         16   \n",
       "88           0.860472          0.684594     89       0.057091         15   \n",
       "40           0.911315          0.698385     41       0.056582         15   \n",
       "4            0.907082          0.615837      5       0.056589         16   \n",
       "\n",
       "    min_child_samples  n_estimators  num_leaves     score  subsample  \n",
       "77                 74           452         425  0.159735   0.820913  \n",
       "3                  83           463         404  0.159740   0.713915  \n",
       "72                 74           466         464  0.159811   0.871708  \n",
       "35                 82           454         417  0.159820   0.771452  \n",
       "96                 86           462         403  0.159855   0.935893  \n",
       "60                 87           454         428  0.159859   0.925825  \n",
       "19                 84           467         453  0.159890   0.747736  \n",
       "88                 81           451         408  0.159899   0.950582  \n",
       "40                 82           458         376  0.159928   0.807325  \n",
       "4                  80           453         384  0.159930   0.824228  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_finer_5.head(10)#.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제출해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tun = LGBMRegressor(n_estimators=452,\n",
    "                         max_depth=15,\n",
    "                         learning_rate=0.056331,\n",
    "                         subsample=0.820913,\n",
    "                         colsample_bylevel=0.883408,\n",
    "                         colsample_bytree=0.680897,\n",
    "                         num_leaves=425,\n",
    "                         min_child_samples=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108567.78137669293"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "y_pred = lgbm_tun.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.expm1(y_pred), np.expm1(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.13987797, 13.07027698, 14.07649284, ..., 13.0887623 ,\n",
       "       12.66086141, 13.02491798])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_tun.fit(train, label)\n",
    "y_pred = lgbm_tun.predict(X_sub)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>4.942906e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>4.744508e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>1.256917e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>3.068664e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>2.861011e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  15035  4.942906e+05\n",
       "1  15036  4.744508e+05\n",
       "2  15037  1.256917e+06\n",
       "3  15038  3.068664e+05\n",
       "4  15039  2.861011e+05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = LetSubmit(np.expm1(y_pred), \"six_lgbm_finetuning_2\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Submission : 113879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딱히 괄목할 만한 성능 향상은 보이지 않는다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다시 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 처음부터 n_estimators를 500까지로 제한해서 시작했으므로 좀 더 높여서 시작해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=5)]: Done 600 out of 600 | elapsed:  4.5min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [400, 600, 800, 1000],\n",
    "    'max_depth': [10, 15, 20, 30, 40, 50],\n",
    "    'learning_rate': [0.055, 0.0575, 0.06, 0.0625, 0.065]\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "grid_lgbm, params_df, rmsle = BestParamsGrid(lgbm, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.055, 'max_depth': 10, 'n_estimators': 600} \tRMSE: 0.1608\n",
      "2: {'learning_rate': 0.06, 'max_depth': 20, 'n_estimators': 600} \tRMSE: 0.1608\n",
      "3: {'learning_rate': 0.06, 'max_depth': 50, 'n_estimators': 600} \tRMSE: 0.1608\n",
      "4: {'learning_rate': 0.06, 'max_depth': 30, 'n_estimators': 600} \tRMSE: 0.1608\n",
      "5: {'learning_rate': 0.06, 'max_depth': 40, 'n_estimators': 600} \tRMSE: 0.1608\n",
      "6: {'learning_rate': 0.055, 'max_depth': 30, 'n_estimators': 600} \tRMSE: 0.1609\n",
      "7: {'learning_rate': 0.055, 'max_depth': 50, 'n_estimators': 600} \tRMSE: 0.1609\n",
      "8: {'learning_rate': 0.055, 'max_depth': 40, 'n_estimators': 600} \tRMSE: 0.1609\n",
      "9: {'learning_rate': 0.055, 'max_depth': 20, 'n_estimators': 600} \tRMSE: 0.1609\n",
      "10: {'learning_rate': 0.0575, 'max_depth': 15, 'n_estimators': 600} \tRMSE: 0.1609\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_lgbm.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 210 candidates, totalling 1050 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=5)]: Done 1003 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=5)]: Done 1050 out of 1050 | elapsed:  6.5min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [500, 550, 575, 600, 625, 650, 700],\n",
    "    'max_depth': [10, 15, 20, 30, 40, 50],\n",
    "    'learning_rate': [0.055, 0.0575, 0.06, 0.0625, 0.065]\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "grid_lgbm, params_df, rmsle = BestParamsGrid(lgbm, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.055, 'max_depth': 10, 'n_estimators': 600} \tRMSE: 0.1608\n",
      "2: {'learning_rate': 0.055, 'max_depth': 10, 'n_estimators': 500} \tRMSE: 0.1608\n",
      "3: {'learning_rate': 0.055, 'max_depth': 10, 'n_estimators': 625} \tRMSE: 0.1608\n",
      "4: {'learning_rate': 0.055, 'max_depth': 10, 'n_estimators': 575} \tRMSE: 0.1608\n",
      "5: {'learning_rate': 0.055, 'max_depth': 10, 'n_estimators': 650} \tRMSE: 0.1608\n",
      "6: {'learning_rate': 0.055, 'max_depth': 10, 'n_estimators': 550} \tRMSE: 0.1608\n",
      "7: {'learning_rate': 0.06, 'max_depth': 50, 'n_estimators': 650} \tRMSE: 0.1608\n",
      "8: {'learning_rate': 0.06, 'max_depth': 40, 'n_estimators': 650} \tRMSE: 0.1608\n",
      "9: {'learning_rate': 0.06, 'max_depth': 20, 'n_estimators': 650} \tRMSE: 0.1608\n",
      "10: {'learning_rate': 0.06, 'max_depth': 30, 'n_estimators': 650} \tRMSE: 0.1608\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_lgbm.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=5)]: Done 960 out of 960 | elapsed:  6.0min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [575, 590, 605, 620, 635, 650],\n",
    "    'max_depth': [5, 7, 9, 11, 13, 15, 20, 30],\n",
    "    'learning_rate': [0.055, 0.0575, 0.06, 0.0625]\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "grid_lgbm, params_df, rmsle = BestParamsGrid(lgbm, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.055, 'max_depth': 11, 'n_estimators': 620} \tRMSE: 0.1607\n",
      "2: {'learning_rate': 0.055, 'max_depth': 11, 'n_estimators': 635} \tRMSE: 0.1608\n",
      "3: {'learning_rate': 0.055, 'max_depth': 11, 'n_estimators': 575} \tRMSE: 0.1608\n",
      "4: {'learning_rate': 0.055, 'max_depth': 11, 'n_estimators': 650} \tRMSE: 0.1608\n",
      "5: {'learning_rate': 0.055, 'max_depth': 11, 'n_estimators': 605} \tRMSE: 0.1608\n",
      "6: {'learning_rate': 0.055, 'max_depth': 11, 'n_estimators': 590} \tRMSE: 0.1608\n",
      "7: {'learning_rate': 0.0575, 'max_depth': 15, 'n_estimators': 635} \tRMSE: 0.1608\n",
      "8: {'learning_rate': 0.06, 'max_depth': 20, 'n_estimators': 650} \tRMSE: 0.1608\n",
      "9: {'learning_rate': 0.06, 'max_depth': 30, 'n_estimators': 650} \tRMSE: 0.1608\n",
      "10: {'learning_rate': 0.06, 'max_depth': 20, 'n_estimators': 620} \tRMSE: 0.1608\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_lgbm.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 좁혀진 범위 중심으로 Finer Search 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\t\t\t\t\n",
      "1 epoch is now calculating . . .\t 0:00:03\n",
      "50 epoch is now calculating . . .\t 0:02:13\n",
      "100 epoch is now calculating . . .\t 0:04:23\n",
      "150 epoch is now calculating . . .\t 0:06:39\n",
      "200 epoch is now calculating . . .\t 0:08:48\n",
      "250 epoch is now calculating . . .\t 0:10:58\n",
      "300 epoch is now calculating . . .\t 0:13:13\n",
      "350 epoch is now calculating . . .\t 0:15:33\n",
      "400 epoch is now calculating . . .\t 0:17:46\n",
      "450 epoch is now calculating . . .\t 0:19:54\n",
      "500 epoch is now calculating . . .\t 0:22:05\n",
      "All Coarse Searching is Finished\n",
      "time duration: 0:22:05\n",
      "(500, 5)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [400, 800],\n",
    "    'max_depth': [10, 40],\n",
    "    'learning_rate': [0.05, 0.06],\n",
    "}\n",
    "\n",
    "lgbm_finer = FinerSearch(train, label, param_grid, 'lgbm', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>446</td>\n",
       "      <td>0.058623</td>\n",
       "      <td>28</td>\n",
       "      <td>744</td>\n",
       "      <td>0.159368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>0.053025</td>\n",
       "      <td>16</td>\n",
       "      <td>746</td>\n",
       "      <td>0.159479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>314</td>\n",
       "      <td>0.058599</td>\n",
       "      <td>30</td>\n",
       "      <td>578</td>\n",
       "      <td>0.159520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>0.053853</td>\n",
       "      <td>21</td>\n",
       "      <td>646</td>\n",
       "      <td>0.159523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>29</td>\n",
       "      <td>791</td>\n",
       "      <td>0.159544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>0.055531</td>\n",
       "      <td>11</td>\n",
       "      <td>660</td>\n",
       "      <td>0.159562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>426</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>28</td>\n",
       "      <td>659</td>\n",
       "      <td>0.159569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>323</td>\n",
       "      <td>0.053776</td>\n",
       "      <td>28</td>\n",
       "      <td>626</td>\n",
       "      <td>0.159595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>289</td>\n",
       "      <td>0.055727</td>\n",
       "      <td>32</td>\n",
       "      <td>536</td>\n",
       "      <td>0.159613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0.052281</td>\n",
       "      <td>10</td>\n",
       "      <td>584</td>\n",
       "      <td>0.159625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  learning_rate  max_depth  n_estimators     score\n",
       "445    446       0.058623         28           744  0.159368\n",
       "189    190       0.053025         16           746  0.159479\n",
       "313    314       0.058599         30           578  0.159520\n",
       "77      78       0.053853         21           646  0.159523\n",
       "260    261       0.054217         29           791  0.159544\n",
       "48      49       0.055531         11           660  0.159562\n",
       "425    426       0.050321         28           659  0.159569\n",
       "322    323       0.053776         28           626  0.159595\n",
       "288    289       0.055727         32           536  0.159613\n",
       "40      41       0.052281         10           584  0.159625"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_finer.head(10)#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>241.700000</td>\n",
       "      <td>0.054595</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>657.000000</td>\n",
       "      <td>0.159540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>147.962495</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>8.206366</td>\n",
       "      <td>82.159736</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>0.159368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>594.500000</td>\n",
       "      <td>0.159521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.054035</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>652.500000</td>\n",
       "      <td>0.159553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>320.750000</td>\n",
       "      <td>0.055678</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>0.159589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.058623</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>791.000000</td>\n",
       "      <td>0.159625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            epoch  learning_rate  max_depth  n_estimators      score\n",
       "count   10.000000      10.000000  10.000000     10.000000  10.000000\n",
       "mean   241.700000       0.054595  23.300000    657.000000   0.159540\n",
       "std    147.962495       0.002622   8.206366     82.159736   0.000075\n",
       "min     41.000000       0.050321  10.000000    536.000000   0.159368\n",
       "25%    106.000000       0.053213  17.250000    594.500000   0.159521\n",
       "50%    275.000000       0.054035  28.000000    652.500000   0.159553\n",
       "75%    320.750000       0.055678  28.750000    723.000000   0.159589\n",
       "max    446.000000       0.058623  32.000000    791.000000   0.159625"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_finer.head(10).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tun = LGBMRegressor(n_estimators=744,\n",
    "                         max_depth=28,\n",
    "                         learning_rate=0.058623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109039.72709429951"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "y_pred = lgbm_tun.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.expm1(y_pred), np.expm1(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.15509942, 13.08171598, 14.06585446, ..., 13.0966762 ,\n",
       "       12.71298993, 13.00234827])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_tun.fit(train, label)\n",
    "y_pred = lgbm_tun.predict(X_sub)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>4.942906e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>4.744508e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>1.256917e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>3.068664e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>2.861011e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  15035  4.942906e+05\n",
       "1  15036  4.744508e+05\n",
       "2  15037  1.256917e+06\n",
       "3  15038  3.068664e+05\n",
       "4  15039  2.861011e+05"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = LetSubmit(np.expm1(y_pred), \"six_lgbm_finetuning_3\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Submission : 111952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tun = LGBMRegressor(n_estimators=746,\n",
    "                         max_depth=16,\n",
    "                         learning_rate=0.053)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131105.5425702168"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "y_pred = lgbm_tun.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.expm1(y_pred), np.expm1(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.12295718, 13.08707634, 14.08961966, ..., 13.08480778,\n",
       "       12.71580981, 12.98786158])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_tun.fit(train, label)\n",
    "y_pred = lgbm_tun.predict(X_sub)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>4.942906e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>4.744508e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>1.256917e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>3.068664e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>2.861011e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  15035  4.942906e+05\n",
       "1  15036  4.744508e+05\n",
       "2  15037  1.256917e+06\n",
       "3  15038  3.068664e+05\n",
       "4  15039  2.861011e+05"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = LetSubmit(np.expm1(y_pred), \"six_lgbm_finetuning_4\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Submission : 111247"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다시 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 안되겠다. Grid Search를 죄다 몽땅 줘버려서 찾아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1920 candidates, totalling 9600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=5)]: Done 1003 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=5)]: Done 1448 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=5)]: Done 1975 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=5)]: Done 2582 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=5)]: Done 3271 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=5)]: Done 4040 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=5)]: Done 4891 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=5)]: Done 5822 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=5)]: Done 6835 tasks      | elapsed: 48.7min\n",
      "[Parallel(n_jobs=5)]: Done 7928 tasks      | elapsed: 57.5min\n",
      "[Parallel(n_jobs=5)]: Done 9103 tasks      | elapsed: 67.2min\n",
      "[Parallel(n_jobs=5)]: Done 9600 out of 9600 | elapsed: 70.7min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000],\n",
    "    'max_depth': [5, 7, 9, 11, 13, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80],\n",
    "    'learning_rate': [0.03, 0.04, 0.05, 0.055, 0.06, 0.065, 0.07, 0.08]\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "grid_lgbm, params_df, rmsle = BestParamsGrid(lgbm, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.04, 'max_depth': 15, 'n_estimators': 900} \tRMSE: 0.1605\n",
      "2: {'learning_rate': 0.04, 'max_depth': 15, 'n_estimators': 850} \tRMSE: 0.1605\n",
      "3: {'learning_rate': 0.04, 'max_depth': 9, 'n_estimators': 800} \tRMSE: 0.1605\n",
      "4: {'learning_rate': 0.04, 'max_depth': 9, 'n_estimators': 850} \tRMSE: 0.1605\n",
      "5: {'learning_rate': 0.04, 'max_depth': 9, 'n_estimators': 900} \tRMSE: 0.1606\n",
      "6: {'learning_rate': 0.04, 'max_depth': 9, 'n_estimators': 950} \tRMSE: 0.1606\n",
      "7: {'learning_rate': 0.04, 'max_depth': 15, 'n_estimators': 800} \tRMSE: 0.1606\n",
      "8: {'learning_rate': 0.04, 'max_depth': 9, 'n_estimators': 1000} \tRMSE: 0.1606\n",
      "9: {'learning_rate': 0.04, 'max_depth': 9, 'n_estimators': 750} \tRMSE: 0.1606\n",
      "10: {'learning_rate': 0.04, 'max_depth': 15, 'n_estimators': 950} \tRMSE: 0.1606\n",
      "11: {'learning_rate': 0.04, 'max_depth': 15, 'n_estimators': 750} \tRMSE: 0.1606\n",
      "12: {'learning_rate': 0.03, 'max_depth': 9, 'n_estimators': 1000} \tRMSE: 0.1607\n",
      "13: {'learning_rate': 0.04, 'max_depth': 13, 'n_estimators': 900} \tRMSE: 0.1607\n",
      "14: {'learning_rate': 0.04, 'max_depth': 50, 'n_estimators': 850} \tRMSE: 0.1607\n",
      "15: {'learning_rate': 0.04, 'max_depth': 45, 'n_estimators': 850} \tRMSE: 0.1607\n",
      "16: {'learning_rate': 0.04, 'max_depth': 20, 'n_estimators': 850} \tRMSE: 0.1607\n",
      "17: {'learning_rate': 0.04, 'max_depth': 70, 'n_estimators': 850} \tRMSE: 0.1607\n",
      "18: {'learning_rate': 0.04, 'max_depth': 40, 'n_estimators': 850} \tRMSE: 0.1607\n",
      "19: {'learning_rate': 0.04, 'max_depth': 25, 'n_estimators': 850} \tRMSE: 0.1607\n",
      "20: {'learning_rate': 0.04, 'max_depth': 30, 'n_estimators': 850} \tRMSE: 0.1607\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_lgbm.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(20):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=5)]: Done 1003 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=5)]: Done 1448 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=5)]: Done 1800 out of 1800 | elapsed: 21.0min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200],\n",
    "    'max_depth': [7, 9, 11, 13, 15, 17, 19, 21],\n",
    "    'learning_rate': [0.03, 0.035, 0.04, 0.045, 0.05]\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "grid_lgbm, params_df, rmsle = BestParamsGrid(lgbm, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.035, 'max_depth': 7, 'n_estimators': 900} \tRMSE: 0.1605\n",
      "2: {'learning_rate': 0.035, 'max_depth': 7, 'n_estimators': 950} \tRMSE: 0.1605\n",
      "3: {'learning_rate': 0.04, 'max_depth': 15, 'n_estimators': 900} \tRMSE: 0.1605\n",
      "4: {'learning_rate': 0.04, 'max_depth': 15, 'n_estimators': 850} \tRMSE: 0.1605\n",
      "5: {'learning_rate': 0.04, 'max_depth': 9, 'n_estimators': 800} \tRMSE: 0.1605\n",
      "6: {'learning_rate': 0.035, 'max_depth': 11, 'n_estimators': 950} \tRMSE: 0.1605\n",
      "7: {'learning_rate': 0.035, 'max_depth': 11, 'n_estimators': 900} \tRMSE: 0.1605\n",
      "8: {'learning_rate': 0.04, 'max_depth': 9, 'n_estimators': 850} \tRMSE: 0.1605\n",
      "9: {'learning_rate': 0.035, 'max_depth': 11, 'n_estimators': 1000} \tRMSE: 0.1605\n",
      "10: {'learning_rate': 0.035, 'max_depth': 7, 'n_estimators': 1000} \tRMSE: 0.1606\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_lgbm.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tun = LGBMRegressor(n_estimators=900,\n",
    "                         max_depth=7,\n",
    "                         learning_rate=0.035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110750.3796780717"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "y_pred = lgbm_tun.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.expm1(y_pred), np.expm1(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.13494496, 13.10383562, 14.08974416, ..., 13.08982018,\n",
       "       12.6919973 , 12.97130319])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_tun.fit(train, label)\n",
    "y_pred = lgbm_tun.predict(X_sub)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>4.942906e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>4.744508e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>1.256917e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>3.068664e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>2.861011e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  15035  4.942906e+05\n",
       "1  15036  4.744508e+05\n",
       "2  15037  1.256917e+06\n",
       "3  15038  3.068664e+05\n",
       "4  15039  2.861011e+05"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = LetSubmit(np.expm1(y_pred), \"lgbm_finetuning_5\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Submission : 110482"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 드디어 성능 향상이....ㅠ.ㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LGBM 최고 점수 : `110482`로 마무리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV - `XGBoost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost도 파라미터 튜닝을 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed: 27.6min\n",
      "[Parallel(n_jobs=5)]: Done 500 out of 500 | elapsed: 30.5min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [200, 500, 800, 1000],\n",
    "    'max_depth': [10, 30, 50, 80, 100],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.5, 1],\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "grid_xgb, params_df, rmsle = BestParamsGrid(xgb, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000} \tRMSE: 0.1623\n",
      "2: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800} \tRMSE: 0.1634\n",
      "3: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200} \tRMSE: 0.1638\n",
      "4: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500} \tRMSE: 0.1641\n",
      "5: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 800} \tRMSE: 0.1642\n",
      "6: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 1000} \tRMSE: 0.1642\n",
      "7: {'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 1000} \tRMSE: 0.1656\n",
      "8: {'learning_rate': 0.01, 'max_depth': 80, 'n_estimators': 1000} \tRMSE: 0.1657\n",
      "9: {'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 1000} \tRMSE: 0.1657\n",
      "10: {'learning_rate': 0.01, 'max_depth': 30, 'n_estimators': 1000} \tRMSE: 0.1659\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_xgb.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 많이 줄었네..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed: 64.0min\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed: 92.2min\n",
      "[Parallel(n_jobs=5)]: Done 900 out of 900 | elapsed: 110.9min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [500, 600, 700, 800, 900, 1000],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1],\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "grid_xgb, params_df, rmsle = BestParamsGrid(xgb, train, label, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'learning_rate': 0.03, 'max_depth': 10, 'n_estimators': 800} \tRMSE: 0.1618\n",
      "2: {'learning_rate': 0.03, 'max_depth': 10, 'n_estimators': 600} \tRMSE: 0.1619\n",
      "3: {'learning_rate': 0.03, 'max_depth': 10, 'n_estimators': 700} \tRMSE: 0.1619\n",
      "4: {'learning_rate': 0.03, 'max_depth': 10, 'n_estimators': 900} \tRMSE: 0.1619\n",
      "5: {'learning_rate': 0.03, 'max_depth': 10, 'n_estimators': 1000} \tRMSE: 0.1619\n",
      "6: {'learning_rate': 0.03, 'max_depth': 10, 'n_estimators': 500} \tRMSE: 0.162\n",
      "7: {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 500} \tRMSE: 0.1622\n",
      "8: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000} \tRMSE: 0.1623\n",
      "9: {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 600} \tRMSE: 0.1623\n",
      "10: {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 700} \tRMSE: 0.1624\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_xgb.cv_results_)\n",
    "results['RMSE'] = np.sqrt(-1 * results.mean_test_score)\n",
    "results = results.sort_values('RMSE').reset_index(inplace=False)\n",
    "for i in range(10):\n",
    "    print(\"{}:\".format(i+1), results.loc[i]['params'], \\\n",
    "          \"\\tRMSE:\", np.round(results.loc[i]['RMSE'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\t\t\t\t\n",
      "1 epoch is now calculating . . .\t 0:00:59\n",
      "30 epoch is now calculating . . .\t 0:26:26\n",
      "60 epoch is now calculating . . .\t 0:53:49\n",
      "90 epoch is now calculating . . .\t 1:19:52\n",
      "120 epoch is now calculating . . .\t 1:46:15\n",
      "150 epoch is now calculating . . .\t 2:12:40\n",
      "180 epoch is now calculating . . .\t 2:38:49\n",
      "210 epoch is now calculating . . .\t 3:04:50\n",
      "240 epoch is now calculating . . .\t 3:29:12\n",
      "270 epoch is now calculating . . .\t 3:54:20\n",
      "300 epoch is now calculating . . .\t 4:19:53\n",
      "All Coarse Searching is Finished\n",
      "time duration: 4:19:53\n",
      "(300, 5)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [700, 900],\n",
    "    'max_depth': [7, 13],\n",
    "    'learning_rate': [0.02, 0.04],\n",
    "}\n",
    "\n",
    "xgb_finer_1 = FinerSearch(train, label, param_grid, 'xgb', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>0.039390</td>\n",
       "      <td>7</td>\n",
       "      <td>793</td>\n",
       "      <td>0.159340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>241</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>7</td>\n",
       "      <td>813</td>\n",
       "      <td>0.159378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>282</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>8</td>\n",
       "      <td>778</td>\n",
       "      <td>0.159389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>0.033804</td>\n",
       "      <td>8</td>\n",
       "      <td>872</td>\n",
       "      <td>0.159414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.039124</td>\n",
       "      <td>7</td>\n",
       "      <td>765</td>\n",
       "      <td>0.159415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  learning_rate  max_depth  n_estimators     score\n",
       "108    109       0.039390          7           793  0.159340\n",
       "240    241       0.033561          7           813  0.159378\n",
       "281    282       0.028396          8           778  0.159389\n",
       "84      85       0.033804          8           872  0.159414\n",
       "95      96       0.039124          7           765  0.159415"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_finer_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', \\\n",
    "            'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', \\\n",
    "            'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'year_month']\n",
    "\n",
    "train = data[features]\n",
    "data['log_price'] = np.log1p(data.price)\n",
    "label = data['log_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tun = XGBRegressor(n_estimators=793,\n",
    "                       max_depth=7,\n",
    "                       learning_rate=0.03939)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123667.24174846783"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2)\n",
    "xgb_tun.fit(X_train, y_train)\n",
    "y_pred = xgb_tun.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.expm1(y_pred), np.expm1(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.168792, 13.01605 , 14.110845, ..., 13.082218, 12.68552 ,\n",
       "       13.031048], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_tun.fit(train, label)\n",
    "y_pred = xgb_tun.predict(X_sub)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>4.942906e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>4.744508e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>1.256917e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>3.068664e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>2.861011e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  15035  4.942906e+05\n",
       "1  15036  4.744508e+05\n",
       "2  15037  1.256917e+06\n",
       "3  15038  3.068664e+05\n",
       "4  15039  2.861011e+05"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = LetSubmit(np.expm1(y_pred), \"xgb_finetuning\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Submission : 107728"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 헉 LGBM보다 더 좋은 성능을 보인다. \n",
    "- XGB 최고 점수 : `107728` 로 마무리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
